{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Dhruv\\\\OneDrive\\\\Desktop\\\\AI-text-detection-web-app\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Dhruv\\\\OneDrive\\\\Desktop\\\\AI-text-detection-web-app'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    train_data_file: Path\n",
    "    test_data_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Text_Detection.constants import *\n",
    "from AI_Text_Detection.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_file=config.train_data_file,\n",
    "            test_data_file=config.test_data_file\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'AI_Text_Detection.entity.config_entity' from 'c:\\\\users\\\\dhruv\\\\onedrive\\\\desktop\\\\ai-text-detection-web-app\\\\src\\\\AI_Text_Detection\\\\entity\\\\config_entity.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import AI_Text_Detection.entity.config_entity as function\n",
    "\n",
    "# Reload function module\n",
    "importlib.reload(function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from AI_Text_Detection import logger\n",
    "from AI_Text_Detection.utils.common import lower_case, remove_punctuation, remove_stopwords, remove_tags\n",
    "from AI_Text_Detection.exception import CustomException\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def initiate_data_transformation(self):\n",
    "        '''\n",
    "        Transform the data and train the model\n",
    "        '''\n",
    "        try: \n",
    "            train_df = pd.read_csv(self.config.train_data_file)\n",
    "            test_df = pd.read_csv(self.config.test_data_file) \n",
    "            logger.info(f\"train and test dataframe loaded\")\n",
    "            logger.info(f\"Data transformation initiated\")\n",
    "            train_df[\"text\"]=train_df[\"text\"].apply(remove_tags)\n",
    "            train_df[\"text\"]=train_df[\"text\"].apply(remove_punctuation)\n",
    "            train_df[\"text\"]=train_df[\"text\"].apply(lower_case)\n",
    "            train_df[\"text\"]=train_df[\"text\"].apply(remove_stopwords)\n",
    "            test_df[\"text\"]=test_df[\"text\"].apply(remove_tags)\n",
    "            test_df[\"text\"]=test_df[\"text\"].apply(remove_punctuation)\n",
    "            test_df[\"text\"]=test_df[\"text\"].apply(lower_case)\n",
    "            test_df[\"text\"]=test_df[\"text\"].apply(remove_stopwords)\n",
    "            X_train = train_df[\"text\"]\n",
    "            y_train = train_df[\"generated\"]\n",
    "            X_test = test_df[\"text\"]\n",
    "            y_test = test_df[\"generated\"]\n",
    "            logger.info(f\"Data transformation completed\")\n",
    "            return X_train, y_train, X_test, y_test\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    X_train, y_train, X_test, y_test = data_transformation.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE_NAME = \"Data Transformation Stage\"\n",
    "\n",
    "class DataTransformationPipeline:\n",
    "    def __init__(self):\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def main(self):\n",
    "        try:\n",
    "            config = ConfigurationManager()\n",
    "            data_transformation_config = config.get_data_transformation_config()\n",
    "            data_transformation = DataTransformation(config=data_transformation_config)\n",
    "            self.X_train, self.y_train, self.X_test, self.y_test = data_transformation.initiate_data_transformation()\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-19 13:01:32,806: INFO: 3222589211: >>>>>> stage Data Transformation Stage started <<<<<<]\n",
      "[2024-03-19 13:01:32,816: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-19 13:01:32,821: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-19 13:01:32,824: INFO: common: created directory at: artifacts]\n",
      "[2024-03-19 13:01:32,824: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2024-03-19 13:02:05,495: INFO: 525598538: train and test dataframe loaded]\n",
      "[2024-03-19 13:02:05,577: INFO: 525598538: Data transformation initiated]\n",
      "[2024-03-19 13:33:10,405: INFO: 525598538: Data transformation completed]\n",
      "[2024-03-19 13:33:10,440: INFO: 3222589211: >>>>>> stage Data Transformation Stage completed <<<<<<\n",
      "\n",
      "x==========x]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n",
    "        obj = DataTransformationPipeline()\n",
    "        obj.main()\n",
    "        logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "97442    1.0\n",
       "97443    1.0\n",
       "97444    0.0\n",
       "97445    0.0\n",
       "97446    1.0\n",
       "Name: generated, Length: 97447, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        real fake feelingsimagine able detect exactly ...\n",
       "1        seeking multiple opinions help make better cho...\n",
       "2        addressnamefebruary 9 2011dear teachernamei th...\n",
       "3        dear teachernameteachername believe cell phone...\n",
       "4        believe computer examine feeling well believe ...\n",
       "                               ...                        \n",
       "97442    senatori writing today express support abolish...\n",
       "97443    car usage popular mode transportation decades ...\n",
       "97444    author suggests studying venus worthwhile purs...\n",
       "97445    schools offering home schooling students losin...\n",
       "97446    deer principal hm writing regarding proposal s...\n",
       "Name: text, Length: 97447, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AItextdetect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
